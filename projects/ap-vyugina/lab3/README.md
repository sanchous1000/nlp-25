# Лабораторная работа №3

## 1. Описание задания
1. Провести эксперименты с моделью SVM и векторными представлениями документов, исследуя влияние разных ядерных функций и моделей, фиксируя метрики точности, полноты, F1-score, accuracy и времени обучения. Определить оптимальное число итераций и лучшую модель. Провести дополнительную серию экспериментов с модификациями векторных представлений, оценивая изменение метрик.

2. Использовать матрицу "термин-документ" для экспериментов с тематическим моделированием LDA, варьируя количество тем.  Зафиксировать топ-10 слов каждой темы, perplexity и вероятности принадлежности документов. Построить график perplexity и определить оптимальное количество тем. 

## 2. Результаты работы

### 2.1 Обучение модели SVM 
- библиотека sklearn
- длина вектора 30
- расчет метрик не библиотечный

**Результаты:**
```
Time: 1.390 s
Class      Precision  Recall     F1        
1          0.5912     0.8305     0.6907    
2          0.9617     0.2515     0.3987    
3          0.5617     0.8941     0.6899    
4          0.863      0.6569     0.746     
Accuracy                         0.657 
```
Не высокая точность достигается по причине небольшого размера вектора, при его увеличении точность растет.

### 2.2 Кросс-валидация классификатора
Для кроссвалидации используется рандомное удаление N признаков из выборки. На графике представлены средние значения precision, recall, f1-score и accuracy для всех классов при увеличивающемся числе удаленных признаков.

<img src=../assets/metrics-feature-drop.png width=400pt>

Посколькоу признаки для удаления выбираются рандомно, могут возникать скачки роста метрик. Однако общий тренд все равно идет к уменьшению метрик.

### 2.3 Тематическое моделирование
- библиотека gensim
- матрица tf-idf получена в результате прошлой лабораторной работы, конвертирована в формат для библиотеки gensim
- число тем варьируется от 1 до 30
- метрика - перплексия (библиотечно считается логарифмическая, затем конвертируется в обычное значение)

**Пример полученных ключевых слов по темам**
```
Тема 0:
39, said, the, iraq, president, two, minister, people, quot, reuters
--------------------------------------------------
Тема 1:
39, software, microsoft, new, internet, the, computer, company, quot, mobile
--------------------------------------------------
Тема 2:
reuters, said, gt, lt, the, oil, 39, new, us, inc
--------------------------------------------------
Тема 3:
39, game, season, the, night, ap, first, new, team, win
--------------------------------------------------
```

**График зависимости перплексии от числа тем**

<img src=../assets/perplexities.png width=400pt>

Также построено приближение полиномом 5-ой степени. Наименьшее значение перплексии - при группировке в 1 тему.