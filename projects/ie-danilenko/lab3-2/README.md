# Лабораторная работа №3.2 (Тематическое моделирование)

## Описание задания

В рамках данной лабораторной работы были выполнены эксперименты с моделью LDA (Latent Dirichlet Allocation) для тематического моделирования документов. Работа состояла из трех основных этапов:

1. **Эксперименты с различным количеством тем и итераций** - проведены эксперименты с LDA с различным количеством тем (2, 5, 10, 20, 40, 4) и разными значениями max_iter (10, 20, 40), зафиксированы топ-10 ключевых слов для каждой темы, perplexity на тестовой выборке и вероятности принадлежности документов к темам.

2. **Построение графика и полиномиальная аппроксимация** - построен график изменения perplexity в зависимости от количества тем, выполнена полиномиальная аппроксимация с выбором оптимальной степени полинома на основе метрики r-squared.

3. **Анализ оптимальных параметров** - на основе собранных экспериментальных данных сформулированы выводы о том, какое количество тем и итераций является оптимальным в соответствии с имеющимися текстовыми данными.

## Использованные технологии и инструменты

### Датасет
- **AG News Dataset** - датасет для классификации новостных текстов
  - Обучающая выборка: 119,999 документов
  - Тестовая выборка: 7,599 документов
  - Количество классов: 4

### Модели и методы
- **LDA (Latent Dirichlet Allocation)** - модель тематического моделирования документов
- **PCA (Principal Component Analysis)** - для сокращения размерности (использовалась в предыдущих работах)

### Библиотеки
- `numpy` >= 1.20.0 - работа с массивами
- `pandas` >= 1.3.0 - обработка данных
- `scikit-learn` >= 1.0.0 - модель LDA
- `scipy` >= 1.7.0 - работа со sparse матрицами
- `matplotlib` >= 3.5.0 - построение графиков
- `tabulate` >= 0.9.0 - форматирование таблиц

### Входные данные
- Матрица "термин-документ" (term-document matrix) из второй лабораторной работы
- Словарь токенов (vocabulary) из второй лабораторной работы
- Аннотированные документы в формате TSV из первой лабораторной работы

## Результаты работы

### 1. Эксперименты с различным количеством тем и итераций

Были проведены эксперименты с LDA для различных комбинаций количества тем и итераций обучения. Для каждого эксперимента зафиксированы:
- Топ-10 ключевых слов для каждой темы
- Perplexity на тестовой выборке
- Вероятности принадлежности документов обучающей выборки к темам
- Время обучения модели

#### Результаты экспериментов с различным количеством тем и итераций

**Таблица: Perplexity для разных комбинаций тем и итераций**

| Количество тем | 10 итераций | 20 итераций | 40 итераций |
|----------------|-------------|-------------|-------------|
| 2              | 692,607.55  | 684,277.62  | 684,028.85  |
| 4              | 1,269,623.61| 1,182,959.03| 1,175,702.98|
| 5              | 1,527,949.69| 1,481,113.24| 1,473,662.42|
| 10             | 3,698,222.59| 3,320,673.19| 3,205,720.93|
| 20             | 10,109,954.64| 8,020,872.04| 7,307,976.39|
| 40             | 32,890,482.49| 20,610,059.92| 17,388,322.60|

**Таблица: Время обучения (секунды) для разных комбинаций тем и итераций**

| Количество тем | 10 итераций | 20 итераций | 40 итераций |
|----------------|-------------|-------------|-------------|
| 2              | 124.6       | 322.5       | 290.3       |
| 4              | 122.7       | 189.5       | 308.0       |
| 5              | 118.4       | 182.3       | 302.1       |
| 10             | 112.7       | 177.6       | 297.0       |
| 20             | 110.7       | 176.3       | 297.6       |
| 40             | 115.2       | 184.5       | 315.2       |

#### Примеры топ-10 ключевых слов для тем

Для модели с 2 темами и 10 итерациями:

**Тема 0:**
- platform (23867.33), 39 (15905.49), sphere (14760.07), # (8237.55), nodded (7993.49), mena (7969.49), marketscore (7382.89), aces (7043.82), airshow (7036.05), nokia (6198.50)

**Тема 1:**
- sphere (29148.93), cell (28804.91), s (28381.02), ds8000 (14377.71), lister (8907.12), chatting (4774.66), anti-cholesterol (4472.49), webmethods (4430.11), afp - afghan (4211.62), conglomerations (4180.16)

*Примечание: числа в скобках - это веса (scores) соответствующих слов в теме.*

### 2. Построение графика и полиномиальная аппроксимация

Был построен график изменения perplexity в зависимости от количества тем для модели с 20 итерациями (исходное значение). Для аппроксимации использовался полином оптимальной степени, выбранной на основе метрики r-squared.

#### Результаты полиномиальной аппроксимации

Для выбора оптимальной степени полинома были проверены степени от 1 до 10. Результаты проверки:

| Степень | R²        |
|---------|-----------|
| 1       | 0.987875  |
| 2       | 0.999917  |
| 3       | 0.999990  |
| 4       | 1.000000  |
| 5       | 1.000000  |
| 6-10    | 1.000000  |

**Выбранная степень**: 5 (минимальная степень с R² = 1.0)

**Параметры аппроксимации**:
- **R-squared**: 1.0 (идеальная аппроксимация)
- **Коэффициенты полинома**: 
  - a₀ = 0.0
  - a₁ = 121,199.25
  - a₂ = 25,697.20
  - a₃ = -1,031.27
  - a₄ = 24.52
  - a₅ = -0.22
- **Формула полинома**: P(x) = 121,199.25x + 25,697.20x² - 1,031.27x³ + 24.52x⁴ - 0.22x⁵

График сохранен в файле `output/perplexity_plot.png`.

#### Анализ зависимости perplexity от количества тем

1. **Увеличение perplexity с ростом количества тем**: С увеличением количества тем perplexity увеличивается, что указывает на усложнение модели и потенциальное переобучение при большом количестве тем.

2. **Зависимость от количества тем** (для 20 итераций): 
   - При 2 темах: perplexity = 684,277.62
   - При 4 темах: perplexity = 1,182,959.03
   - При 5 темах: perplexity = 1,481,113.24
   - При 10 темах: perplexity = 3,320,673.19
   - При 20 темах: perplexity = 8,020,872.04
   - При 40 темах: perplexity = 20,610,059.92

3. **Влияние количества итераций**: С увеличением количества итераций perplexity уменьшается для всех значений количества тем, что указывает на улучшение сходимости модели при большем количестве итераций.

4. **Полиномиальная аппроксимация**: Полином 5-й степени обеспечивает идеальную аппроксимацию (R² = 1.0), что указывает на четкую математическую зависимость между количеством тем и perplexity.

### 3. Анализ оптимальных параметров

#### Оптимальное количество тем

На основе анализа результатов экспериментов:

**Выводы:**
1. **Perplexity увеличивается с увеличением количества тем** - это указывает на то, что при большом количестве тем модель становится более сложной и может хуже обобщать данные на тестовой выборке.

2. **Оптимальное количество тем зависит от задачи**:
   - Если цель - минимизировать perplexity, то оптимальным является **минимальное количество тем (2)**
   - При 2 темах perplexity минимален (684,028.85 при 40 итерациях)
   - С увеличением количества тем perplexity значительно возрастает (от 684,028.85 для 2 тем до 17,388,322.60 для 40 тем при 40 итерациях)
   - Количество тем, равное количеству классов (4), показало perplexity = 1,182,959.03 (при 20 итерациях)

3. **Рекомендации**:
   - Для данной задачи оптимальным количеством тем является **2-4**, так как это обеспечивает минимальный perplexity
   - Количество тем, равное количеству классов (4), показало промежуточные результаты и может быть использовано для задач классификации
   - При большом количестве тем (20-40) perplexity значительно возрастает, что указывает на переобучение модели

#### Оптимальное количество итераций

**Выводы:**
1. **Влияние количества итераций на perplexity**: С увеличением количества итераций perplexity уменьшается для всех значений количества тем, что указывает на улучшение сходимости модели:
   - Для 2 тем: 692,607.55 (10 iter) → 684,277.62 (20 iter) → 684,028.85 (40 iter) - улучшение на 1.2%
   - Для 4 тем: 1,269,623.61 (10 iter) → 1,182,959.03 (20 iter) → 1,175,702.98 (40 iter) - улучшение на 7.4%
   - Для 40 тем: 32,890,482.49 (10 iter) → 20,610,059.92 (20 iter) → 17,388,322.60 (40 iter) - улучшение на 47.1%

2. **Влияние количества итераций на время обучения**: Время обучения варьируется в зависимости от количества тем и итераций:
   - 10 итераций: ~110-125 секунд
   - 20 итераций: ~175-325 секунд
   - 40 итераций: ~290-315 секунд

3. **Оптимальное количество итераций**: 
   - **40 итераций** является оптимальным для минимизации perplexity, так как обеспечивает наилучшее качество модели для всех значений количества тем
   - Увеличение количества итераций с 10 до 20 дает значительное улучшение perplexity
   - Дальнейшее увеличение до 40 итераций дает дополнительное, но менее значительное улучшение
   - Для практического применения можно использовать **20 итераций** как компромисс между качеством и временем обучения

### Общие выводы

1. **Выбор количества тем**: Для тематического моделирования документов из датасета AG News оптимальным является **минимальное количество тем (2)**, так как это обеспечивает минимальный perplexity. Количество тем, равное количеству классов (4), также показывает приемлемые результаты.

2. **Выбор количества итераций**: **40 итераций** является оптимальным значением для минимизации perplexity, хотя **20 итераций** может быть использовано как компромисс между качеством и временем обучения.

3. **Зависимость perplexity от количества тем**: Perplexity увеличивается с увеличением количества тем, что указывает на усложнение модели и потенциальное переобучение при большом количестве тем.

4. **Полиномиальная аппроксимация**: Полином 5-й степени обеспечивает идеальную аппроксимацию зависимости perplexity от количества тем (R² = 1.0), что указывает на четкую математическую закономерность.

5. **Влияние количества итераций**: Увеличение количества итераций приводит к улучшению perplexity для всех значений количества тем, что указывает на важность достаточного количества итераций для сходимости алгоритма LDA.

## Инструкция по запуску

### Требования

1. Python 3.8+
2. Установленные зависимости из `requirements.txt`

### Установка зависимостей

```bash
cd projects/ie-danilenko/lab3-2/source
pip install -r requirements.txt
```

### Подготовка данных

1. Убедитесь, что выполнены предыдущие лабораторные работы:
   - Матрица "термин-документ" (`output/term_document_matrix.json`)
   - Словарь токенов (`output/vocabulary.json`)
   - Аннотированные документы (`assets/annotated-corpus/train/` и `assets/annotated-corpus/test/`)

2. Если данные отсутствуют, выполните скрипты из предыдущих лабораторных работ для их создания.

### Запуск экспериментов

#### 1. Эксперименты с LDA

```bash
python lda_experiments.py
```

Параметры по умолчанию:
- Количество тем: 2, 5, 10, 20, 40, 4 (количество классов)
- Количество итераций: 10, 20, 40
- Выходной файл: `output/lda_experiments_results.json`

Скрипт автоматически:
- Загружает матрицу "термин-документ" и словарь
- Строит матрицу для тестовой выборки
- Проводит эксперименты для всех комбинаций параметров
- Сохраняет результаты в JSON файл
- Выводит сравнительные таблицы perplexity и времени обучения
- Формулирует выводы об оптимальных параметрах

#### 2. Построение графика perplexity

```bash
python plot_perplexity.py
```

Параметры по умолчанию:
- Используются результаты для 20 итераций (исходное значение)
- Выходной файл графика: `output/perplexity_plot.png`
- Выходной файл информации об аппроксимации: `output/polynomial_approximation_info.json`

Скрипт автоматически:
- Загружает результаты экспериментов
- Находит оптимальную степень полинома на основе r-squared
- Строит график с экспериментальными данными и полиномиальной аппроксимацией
- Сохраняет график и информацию об аппроксимации

### Просмотр результатов

Результаты сохраняются в JSON файлах в директории `output/`:
- `lda_experiments_results.json` - результаты всех экспериментов с LDA
- `perplexity_plot.png` - график изменения perplexity
- `polynomial_approximation_info.json` - информация о полиномиальной аппроксимации

Результаты также выводятся в консоль в виде таблиц с использованием библиотеки `tabulate`.

### Структура проекта

```
lab3-2/
├── source/
│   ├── lda_experiments.py                    # Эксперименты с LDA
│   ├── plot_perplexity.py                    # Построение графика perplexity
│   ├── requirements.txt                      # Зависимости
│   ├── assets/
│   │   └── annotated-corpus/                 # Аннотированные документы
│   │       ├── train/                        # Обучающая выборка
│   │       └── test/                          # Тестовая выборка
│   ├── dataset/                              # Датасет
│   │   ├── train.csv
│   │   └── test.csv
│   └── output/                               # Результаты
│       ├── term_document_matrix.json         # Матрица термин-документ
│       ├── vocabulary.json                    # Словарь токенов
│       ├── lda_experiments_results.json     # Результаты экспериментов
│       ├── perplexity_plot.png              # График perplexity
│       └── polynomial_approximation_info.json
├── task3-2.md                                # Задание
└── README.md                                 # Этот файл
```