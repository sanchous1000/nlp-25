# Лабораторная работа №3.1 (Классификация текстов)

## Описание задания

В рамках данной лабораторной работы были выполнены эксперименты с моделью SVM (Support Vector Machine) для многоклассовой классификации текстовых документов. Работа состояла из трех основных этапов:

1. **Эксперименты с различными kernel functions и количеством итераций** - проведены эксперименты с SVM с различными ядерными функциями (linear, rbf, poly) и разными значениями max_iter (100, 500, 1000), а также сравнение с моделью MLP.

2. **Анализ оптимальных параметров** - на основе полученных метрик определены оптимальные значения параметров модели.

3. **Эксперименты с преобразованием векторных представлений** - проведена серия экспериментов с сокращением размерности векторных представлений документов с использованием PCA и анализ зависимости метрик от размерности.

## Использованные технологии и инструменты

### Датасет
- **AG News Dataset** - датасет для классификации новостных текстов
  - Обучающая выборка: 119,999 документов
  - Тестовая выборка: 7,599 документов
  - Количество классов: 4

### Модели и методы
- **SVM (Support Vector Machine)** с различными kernel functions:
  - Linear kernel
  - RBF (Radial Basis Function) kernel
  - Polynomial kernel
- **MLP (Multi-Layer Perceptron)** - для сравнения с SVM
- **PCA (Principal Component Analysis)** - для сокращения размерности векторных представлений

### Библиотеки
- `numpy` >= 1.20.0 - работа с массивами
- `pandas` >= 1.3.0 - обработка данных
- `scikit-learn` >= 1.0.0 - модели машинного обучения (SVM, MLP, PCA, StandardScaler)
- `tabulate` >= 0.9.0 - форматирование таблиц

### Векторные представления
- Использованы векторные представления документов, полученные во второй лабораторной работе
- Размерность исходных векторов: 100
- Метод векторизации: GloVe (Global Vectors for Word Representation)

## Результаты работы

### 1. Эксперименты с различными kernel functions и max_iter

Были проведены эксперименты с тремя kernel functions (linear, rbf, poly) и тремя значениями max_iter (100, 500, 1000), а также эксперименты с MLP для сравнения.

#### Результаты экспериментов с SVM и MLP

| Модель | Kernel/Layers | Max Iter | Accuracy | Precision | Recall | F1-score | Time (s) |
|--------|---------------|----------|----------|-----------|--------|----------|----------|
| SVM    | linear        | 100      | 0.2524   | 0.2522    | 0.2524 | 0.2395   | 5.26     |
| SVM    | linear        | 500      | 0.2537   | 0.2433    | 0.2537 | 0.1562   | 20.41    |
| SVM    | linear        | 1000     | 0.2452   | 0.2142    | 0.2451 | 0.1277   | 38.27    |
| SVM    | rbf           | 100      | 0.2500   | 0.2476    | 0.2500 | 0.1988   | 6.06     |
| SVM    | rbf           | 500      | 0.2461   | 0.2422    | 0.2461 | 0.2146   | 30.07    |
| SVM    | rbf           | 1000     | 0.2457   | 0.2444    | 0.2457 | 0.2245   | 62.38    |
| SVM    | poly          | 100      | 0.2500   | 0.0625    | 0.2500 | 0.1000   | 5.78     |
| SVM    | poly          | 500      | 0.2496   | 0.0625    | 0.2496 | 0.1000   | 28.07    |
| SVM    | poly          | 1000     | 0.2496   | 0.3451    | 0.2496 | 0.1008   | 57.44    |
| MLP    | (100,)        | 100      | 0.2498   | 0.2500    | 0.2498 | 0.2461   | 2.31     |
| MLP    | (100,)        | 500      | 0.2498   | 0.2500    | 0.2498 | 0.2461   | 2.53     |
| MLP    | (100,)        | 1000     | 0.2498   | 0.2500    | 0.2498 | 0.2461   | 2.34     |

#### Анализ результатов первого этапа

**Оптимальные параметры:**
- **Лучшая модель по F1-score**: MLP с max_iter=100 (F1-score = 0.2461)
- **Лучшая SVM модель по F1-score**: SVM с linear kernel и max_iter=100 (F1-score = 0.2395)
- **Оптимальное количество итераций для SVM linear**: 100 (лучший баланс между качеством и временем обучения)

**Наблюдения:**
1. **Linear kernel** показал лучшие результаты среди kernel functions для SVM, особенно при max_iter=100
2. **RBF kernel** показал улучшение F1-score с увеличением количества итераций (0.1988 → 0.2245)
3. **Polynomial kernel** показал низкие результаты (F1-score ≈ 0.10), что может указывать на несоответствие параметров ядра данным
4. **MLP** показал стабильные и лучшие результаты по F1-score, при этом время обучения значительно меньше, чем у SVM

### 2. Эксперименты с сокращением размерности

Были проведены эксперименты с сокращением размерности векторных представлений с использованием PCA. Использовалась модель SVM с linear kernel и max_iter=100 (оптимальное значение, найденное на первом этапе).

#### Результаты экспериментов с сокращением размерности

| Размерность | Explained Variance | Accuracy | Precision | Recall | F1-score | Time (s) |
|-------------|-------------------|----------|-----------|--------|----------|----------|
| 100         | 1.0000            | 0.2524   | 0.2522    | 0.2524 | 0.2395   | 5.01     |
| 10          | 0.1212            | 0.2479   | 0.2479    | 0.2479 | 0.2461   | 0.50     |
| 20          | 0.2323            | 0.2473   | 0.2468    | 0.2473 | 0.2253   | 0.90     |
| 30          | 0.3391            | 0.2483   | 0.2507    | 0.2483 | 0.1976   | 1.31     |
| 40          | 0.4425            | 0.2492   | 0.2452    | 0.2492 | 0.1938   | 1.86     |
| 50          | 0.5426            | 0.2481   | 0.2490    | 0.2481 | 0.2178   | 2.50     |
| 75          | 0.7805            | 0.2521   | 0.2511    | 0.2521 | 0.2181   | 3.74     |
| 99          | 0.9917            | 0.2571   | 0.2544    | 0.2571 | 0.2320   | 5.01     |

#### Анализ зависимости метрик от размерности

**Оптимальная размерность**: 10 компонент
- **F1-score**: 0.2461 (улучшение на +0.0066 по сравнению с исходной размерностью)
- **Accuracy**: 0.2479 (незначительное снижение на -0.0045)
- **Explained Variance**: 0.1212 (12.12%)

**Характер зависимости метрик от размерности:**

1. **F1-score**: 
   - Максимальное значение достигается при размерности 10 (0.2461)
   - При увеличении размерности до 20-40 наблюдается снижение F1-score (0.2253 → 0.1938)
   - При размерности 50-75 F1-score повышается до 0.2178-0.2181
   - При размерности 99 F1-score (0.2320) ниже, чем при исходной размерности 100 (0.2395), но выше, чем при промежуточных размерностях

2. **Accuracy**: 
   - Остается относительно стабильной (0.247-0.257) для всех размерностей
   - Максимальное значение достигается при размерности 99 (0.2571)
   - Незначительные колебания не показывают четкой зависимости от размерности

3. **Precision**: 
   - Варьируется от 0.2452 до 0.2544
   - Максимальное значение при размерности 99 (0.2544)
   - При размерности 10 precision (0.2479) близка к исходной (0.2522)

4. **Recall**: 
   - Остается стабильным (0.247-0.257) для всех размерностей
   - Максимальное значение при размерности 99 (0.2571)
   - При размерности 10 recall (0.2479) близок к исходному (0.2524)

5. **Explained Variance**: 
   - При размерности 10 сохраняется только 12.12% дисперсии
   - При размерности 50 сохраняется 54.26% дисперсии
   - При размерности 99 сохраняется 99.17% дисперсии

## Выводы

### По первому этапу (сравнение моделей и kernel functions)

1. **Оптимальная модель**: MLP показал лучшие результаты по F1-score (0.2461) среди всех протестированных моделей.

2. **Оптимальная SVM конфигурация**: SVM с linear kernel и max_iter=100 показал лучший F1-score (0.2395) среди всех вариантов SVM.

3. **Влияние количества итераций**:
   - Для linear kernel: увеличение max_iter с 100 до 500 ухудшает F1-score (0.2395 → 0.1562), но незначительно улучшает accuracy (0.2524 → 0.2537)
   - Для rbf kernel: увеличение max_iter улучшает F1-score (0.1988 → 0.2245), при этом accuracy остается стабильной (0.2500 → 0.2457)
   - Для MLP: количество итераций не влияет на результаты (возможно, модель сходится очень быстро)

4. **Сравнение kernel functions**:
   - Linear kernel показал лучшие результаты для данной задачи (F1-score = 0.2395 при max_iter=100)
   - RBF kernel требует больше итераций для достижения хороших результатов (F1-score улучшается с 0.1988 до 0.2245)
   - Polynomial kernel показал неудовлетворительные результаты (F1-score ≈ 0.10), возможно, требуется настройка параметров

5. **Сравнение метрик**:
   - MLP показал стабильные результаты по всем метрикам (accuracy = 0.2498, precision = 0.2500, recall = 0.2498, F1-score = 0.2461)
   - SVM с linear kernel при max_iter=100 показал лучший баланс метрик среди SVM моделей

### По второму этапу (сокращение размерности)

1. **Влияние сокращения размерности**: Сокращение размерности с 100 до 10 компонент **улучшило** F1-score с 0.2395 до 0.2461, несмотря на то, что сохраняется только 12.12% дисперсии. Это может указывать на:
   - Наличие шума в исходных векторах, который удаляется при PCA
   - Переобучение модели на исходных данных
   - Более эффективное использование информативных признаков после PCA

2. **Оптимальная размерность**: 10 компонент обеспечивает:
   - Лучший F1-score (0.2461) среди всех протестированных размерностей
   - Accuracy близкую к исходной (0.2479 vs 0.2524)
   - Precision и Recall на уровне исходной размерности (0.2479 vs 0.2522/0.2524)

3. **Зависимость метрик от размерности**:
   - F1-score не монотонно зависит от размерности, оптимальное значение достигается при размерности 10
   - При увеличении размерности до 20-40 наблюдается снижение F1-score (0.2253 → 0.1938)
   - При размерности 50-75 F1-score повышается до 0.2178-0.2181
   - При размерности 99 F1-score (0.2320) ниже исходной (0.2395), но выше промежуточных значений
   - Accuracy остается относительно стабильной (0.247-0.257) для всех размерностей, максимальное значение при размерности 99

4. **Влияние объясненной дисперсии**:
   - При размерности 10 сохраняется только 12.12% дисперсии, но качество модели улучшается
   - При размерности 50 сохраняется 54.26% дисперсии, F1-score = 0.2178
   - При размерности 99 сохраняется 99.17% дисперсии, F1-score = 0.2320 (ниже исходной, но выше промежуточных)

5. **Практические рекомендации**:
   - Для данной задачи сокращение размерности до 10 компонент является оптимальным по F1-score
   - При необходимости сохранения большего количества информации можно использовать размерность 50-75 (сохраняется 54-78% дисперсии)
   - Сокращение размерности может улучшить качество модели за счет удаления шума и избыточных признаков

### Общие выводы

1. **Выбор модели**: Для данной задачи MLP показал лучшие результаты по F1-score (0.2461), но SVM с linear kernel также показал хорошие результаты (F1-score = 0.2395) при правильной настройке параметров.

2. **Влияние сокращения размерности**: Сокращение размерности с помощью PCA может улучшить качество модели за счет удаления шума и избыточных признаков. Оптимальная размерность (10 компонент) показала улучшение F1-score на 2.8% по сравнению с исходной размерностью (0.2395 → 0.2461).

3. **Важность настройки гиперпараметров**: Количество итераций и выбор kernel function критически важны для качества модели SVM. Для linear kernel оптимальным является max_iter=100, для rbf kernel - max_iter=1000.

4. **Сравнение kernel functions**: Linear kernel показал лучшие результаты для данной задачи классификации текстов, в то время как polynomial kernel требует дополнительной настройки параметров.

## Инструкция по запуску

### Требования

1. Python 3.8+
2. Установленные зависимости из `requirements.txt`

### Установка зависимостей

```bash
cd projects/ie-danilenko/lab3/source
pip install -r requirements.txt
```

### Подготовка данных

1. Убедитесь, что векторные представления документов созданы (файлы `output/train_vectors.tsv` и `output/test_vectors.tsv`)

2. Если векторы отсутствуют, создайте их, используя скрипты из предыдущих лабораторных работ или другие инструменты для векторизации документов.

### Запуск экспериментов

#### 1. Эксперименты с различными kernel functions и max_iter

```bash
python svm_classification_experiments.py
```

Параметры по умолчанию:
- Kernel functions: linear, rbf, poly
- Max iterations: 100, 500, 1000
- Выходной файл: `output/svm_experiments.json`

Для изменения параметров:
```bash
python svm_classification_experiments.py --kernels linear rbf --max-iters 100 500 1000
```

#### 2. Эксперименты с сокращением размерности

```bash
python dimension_reduction_experiments.py --kernel linear --max-iter 100
```

Параметры по умолчанию:
- Размерности: 10, 20, 30, 40, 50, 75, 99
- Kernel: linear
- Max iter: 100 (оптимальное значение, найденное на первом этапе)
- Выходной файл: `output/dimension_reduction_experiments.json`

Для изменения размерностей:
```bash
python dimension_reduction_experiments.py --dimensions 10 25 50 75 100 --kernel linear --max-iter 100
```

### Просмотр результатов

Результаты сохраняются в JSON файлах в директории `output/`:
- `svm_experiments.json` - результаты экспериментов с различными моделями
- `dimension_reduction_experiments.json` - результаты экспериментов с сокращением размерности

Результаты также выводятся в консоль в виде таблиц с использованием библиотеки `tabulate`.

### Структура проекта

```
lab3/
├── source/
│   ├── svm_classification_experiments.py      # Эксперименты с SVM и MLP
│   ├── dimension_reduction_experiments.py     # Эксперименты с PCA
│   ├── requirements.txt                      # Зависимости
│   ├── dataset/                              # Датасет
│   │   ├── train.csv
│   │   └── test.csv
│   └── output/                               # Результаты
│       ├── train_vectors.tsv
│       ├── test_vectors.tsv
│       ├── svm_experiments.json
│       └── dimension_reduction_experiments.json
└── README.md                                 # Этот файл
```

**Примечание:** Векторные представления документов (`train_vectors.tsv` и `test_vectors.tsv`) должны быть созданы заранее (в рамках предыдущих лабораторных работ). Скрипты для векторизации не входят в состав данной лабораторной работы.

## Примечания

- Все метрики (precision, recall, f1-score, accuracy) вычисляются вручную без использования библиотечных методов, как требуется в задании
- Время обучения измеряется для каждого эксперимента отдельно
- Результаты могут незначительно отличаться при повторном запуске из-за случайности в алгоритмах

