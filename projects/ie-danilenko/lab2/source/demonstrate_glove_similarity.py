"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ GloVe —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è.
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –±–ª–∏–∑–∫–∏—Ö —Å–ª–æ–≤ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä—ã,
–¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–Ω—å—à–µ, —á–µ–º –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –¥–∞–ª–µ–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤.
"""

import numpy as np
import argparse
from pathlib import Path
from text_to_glove import (
    initialize_glove_model,
    get_device,
    GloVeModel
)


def cosine_distance(vec1, vec2):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –¥–≤—É–º—è –≤–µ–∫—Ç–æ—Ä–∞–º–∏.
    
    –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ = 1 - –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
    –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ = (A ¬∑ B) / (||A|| * ||B||)
    
    Args:
        vec1: –ü–µ—Ä–≤—ã–π –≤–µ–∫—Ç–æ—Ä
        vec2: –í—Ç–æ—Ä–æ–π –≤–µ–∫—Ç–æ—Ä
        
    Returns:
        –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–æ—Ç 0 –¥–æ 2, –≥–¥–µ 0 - –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä—ã)
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–µ–∫—Ç–æ—Ä—ã –Ω–µ –Ω—É–ª–µ–≤—ã–µ
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    
    if norm1 == 0 or norm2 == 0:
        return 2.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –Ω—É–ª–µ–≤—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤
    
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
    dot_product = np.dot(vec1, vec2)
    cosine_similarity = dot_product / (norm1 * norm2)
    
    # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ = 1 - –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
    # –†–µ–∑—É–ª—å—Ç–∞—Ç –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 2], –≥–¥–µ 0 - –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä—ã
    cosine_distance = 1.0 - cosine_similarity
    
    return cosine_distance


def get_word_vector(word, glove_model):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞ –∏–∑ –º–æ–¥–µ–ª–∏ GloVe.
    
    Args:
        word: –°–ª–æ–≤–æ (–≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ)
        glove_model: –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å GloVe
        
    Returns:
        –í–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ –∏–ª–∏ None, –µ—Å–ª–∏ —Å–ª–æ–≤–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Å–ª–æ–≤–∞—Ä–µ
    """
    word_lower = word.lower()
    if word_lower not in glove_model.word_to_id:
        return None
    
    embeddings = glove_model.get_embeddings().cpu().numpy()
    word_id = glove_model.word_to_id[word_lower]
    return embeddings[word_id]


def find_similar_words(
    target_word,
    candidate_words,
    glove_model,
    top_k=None
):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–µ —Å–ª–æ–≤–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–º—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é.
    
    Args:
        target_word: –ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ
        candidate_words: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        glove_model: –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å GloVe
        top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (None - –≤–µ—Ä–Ω—É—Ç—å –≤—Å–µ)
        
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (—Å–ª–æ–≤–æ, –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ_—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ), –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
    """
    target_vector = get_word_vector(target_word, glove_model)
    if target_vector is None:
        return []
    
    distances = []
    for word in candidate_words:
        word_vector = get_word_vector(word, glove_model)
        if word_vector is not None:
            dist = cosine_distance(target_vector, word_vector)
            distances.append((word, dist))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è (–º–µ–Ω—å—à–µ = –±–ª–∏–∂–µ)
    distances.sort(key=lambda x: x[1])
    
    if top_k is not None:
        return distances[:top_k]
    return distances


def demonstrate_word_similarity(
    target_word,
    similar_words,
    same_domain_words,
    different_words,
    glove_model
):
    """
    –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≥—Ä—É–ø–ø —Å–ª–æ–≤.
    
    Args:
        target_word: –ò—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ
        similar_words: –°–ª–æ–≤–∞ —Å –ø–æ—Ö–æ–∂–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
        same_domain_words: –°–ª–æ–≤–∞ –∏–∑ —Ç–æ–π –∂–µ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏
        different_words: –°–ª–æ–≤–∞ —Å —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –¥—Ä—É–≥–∏–º–∏ —Å–≤–æ–π—Å—Ç–≤–∞–º–∏
        glove_model: –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å GloVe
    """
    print(f"\n{'='*80}")
    print(f"–ê–Ω–∞–ª–∏–∑ —Å–ª–æ–≤–∞: '{target_word}'")
    print(f"{'='*80}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞
    target_vector = get_word_vector(target_word, glove_model)
    if target_vector is None:
        print(f"‚ö†Ô∏è  –°–ª–æ–≤–æ '{target_word}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Å–ª–æ–≤–∞—Ä–µ –º–æ–¥–µ–ª–∏!")
        return
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –∏ –∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    all_words = []
    all_words.extend([(word, "–ü–æ—Ö–æ–∂–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ") for word in similar_words])
    all_words.extend([(word, "–¢–∞ –∂–µ –æ–±–ª–∞—Å—Ç—å") for word in same_domain_words])
    all_words.extend([(word, "–î—Ä—É–≥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ") for word in different_words])
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
    results = []
    for word, category in all_words:
        word_vector = get_word_vector(word, glove_model)
        if word_vector is None:
            results.append((word, category, None, "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Å–ª–æ–≤–∞—Ä–µ"))
        else:
            dist = cosine_distance(target_vector, word_vector)
            results.append((word, category, dist, None))
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–æ–≤–∞, –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≤ —Å–ª–æ–≤–∞—Ä–µ
    valid_results = [(w, c, d, _) for w, c, d, _ in results if d is not None]
    not_found = [(w, c) for w, c, _, msg in results if msg is not None]
    
    if not_found:
        print(f"\n‚ö†Ô∏è  –°–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Å–ª–æ–≤–∞—Ä–µ: {', '.join([w for w, _ in not_found])}")
    
    if not valid_results:
        print("\n‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–ª–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è!")
        return
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é
    valid_results.sort(key=lambda x: x[2])
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\n–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –ø–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–º—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é:")
    print(f"{'–†–∞–Ω–≥':<6} {'–°–ª–æ–≤–æ':<20} {'–ö–∞—Ç–µ–≥–æ—Ä–∏—è':<25} {'–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ':<25}")
    print("-" * 80)
    
    for rank, (word, category, distance, _) in enumerate(valid_results, 1):
        print(f"{rank:<6} {word:<20} {category:<25} {distance:<25.6f}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    
    similar_distances = [d for _, c, d, _ in valid_results if c == "–ü–æ—Ö–æ–∂–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"]
    domain_distances = [d for _, c, d, _ in valid_results if c == "–¢–∞ –∂–µ –æ–±–ª–∞—Å—Ç—å"]
    different_distances = [d for _, c, d, _ in valid_results if c == "–î—Ä—É–≥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ"]
    
    if similar_distances:
        avg_similar = np.mean(similar_distances)
        print(f"  –ü–æ—Ö–æ–∂–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:    —Å—Ä–µ–¥–Ω–µ–µ = {avg_similar:.6f}, "
              f"–º–∏–Ω = {min(similar_distances):.6f}, –º–∞–∫—Å = {max(similar_distances):.6f}")
    
    if domain_distances:
        avg_domain = np.mean(domain_distances)
        print(f"  –¢–∞ –∂–µ –æ–±–ª–∞—Å—Ç—å:       —Å—Ä–µ–¥–Ω–µ–µ = {avg_domain:.6f}, "
              f"–º–∏–Ω = {min(domain_distances):.6f}, –º–∞–∫—Å = {max(domain_distances):.6f}")
    
    if different_distances:
        avg_different = np.mean(different_distances)
        print(f"  –î—Ä—É–≥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:     —Å—Ä–µ–¥–Ω–µ–µ = {avg_different:.6f}, "
              f"–º–∏–Ω = {min(different_distances):.6f}, –º–∞–∫—Å = {max(different_distances):.6f}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã
    print(f"\n‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã:")
    checks = []
    
    if similar_distances and domain_distances:
        max_similar = max(similar_distances)
        min_domain = min(domain_distances)
        check1 = max_similar < min_domain
        checks.append(check1)
        status1 = "‚úì" if check1 else "‚úó"
        print(f"  {status1} –ü–æ—Ö–æ–∂–∏–µ < –¢–∞ –∂–µ –æ–±–ª–∞—Å—Ç—å: "
              f"max(–ø–æ—Ö–æ–∂–∏–µ)={max_similar:.6f} < min(–æ–±–ª–∞—Å—Ç—å)={min_domain:.6f}")
    
    if domain_distances and different_distances:
        max_domain = max(domain_distances)
        min_different = min(different_distances)
        check2 = max_domain < min_different
        checks.append(check2)
        status2 = "‚úì" if check2 else "‚úó"
        print(f"  {status2} –¢–∞ –∂–µ –æ–±–ª–∞—Å—Ç—å < –î—Ä—É–≥–æ–µ: "
              f"max(–æ–±–ª–∞—Å—Ç—å)={max_domain:.6f} < min(–¥—Ä—É–≥–æ–µ)={min_different:.6f}")
    
    if all(checks):
        print(f"\nüéâ –ì–∏–ø–æ—Ç–µ–∑–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞! –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –±–ª–∏–∑–∫–∏–µ —Å–ª–æ–≤–∞ –∏–º–µ—é—Ç –º–µ–Ω—å—à–µ–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ.")
    else:
        print(f"\n‚ö†Ô∏è  –ì–∏–ø–æ—Ç–µ–∑–∞ —á–∞—Å—Ç–∏—á–Ω–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∞. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –æ–∂–∏–¥–∞–Ω–∏—è–º.")


if __name__ == "__main__":
    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    parser = argparse.ArgumentParser(
        description='–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ GloVe —Å –∫–æ—Å–∏–Ω—É—Å–Ω—ã–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ–º'
    )
    parser.add_argument(
        '--model',
        type=str,
        default=None,
        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏ GloVe (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: output/glove_model.pkl)'
    )
    
    args = parser.parse_args()
    
    # –ü—É—Ç–∏
    base_dir = Path(__file__).parent
    
    if args.model:
        model_path = Path(args.model)
        if not model_path.is_absolute():
            model_path = base_dir / model_path
    else:
        model_path = base_dir / "output" / "glove_model.pkl"
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    device = get_device()
    
    print("=" * 80)
    print("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ GloVe —Å –∫–æ—Å–∏–Ω—É—Å–Ω—ã–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ–º")
    print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    print("\n1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ GloVe...")
    print(f"   –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏: {model_path}")
    glove_model, word_to_id = initialize_glove_model(
        model_path=model_path,
        device=device,
        retrain=False
    )
    
    print(f"   –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {len(word_to_id)} —Ç–æ–∫–µ–Ω–æ–≤")
    print(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤: {glove_model.embedding_dim}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –Ω–∞–±–æ—Ä—ã —Å–ª–æ–≤
    # –ö–∞–∂–¥—ã–π –Ω–∞–±–æ—Ä —Å–æ–¥–µ—Ä–∂–∏—Ç: –∏—Å—Ö–æ–¥–Ω–æ–µ —Å–ª–æ–≤–æ, –ø–æ—Ö–æ–∂–∏–µ, –∏–∑ —Ç–æ–π –∂–µ –æ–±–ª–∞—Å—Ç–∏, —Ä–∞–∑–Ω—ã–µ
    
    test_cases = [
        {
            'target': 'cat',
            'similar': ['tiger', 'feline', 'kitten'],
            'same_domain': ['animal', 'rabbit', 'dog'],
            'different': ['sentence', 'creation', 'computer']
        },
        {
            'target': 'president',
            'similar': ['leader', 'chief', 'executive'],
            'same_domain': ['government', 'politics', 'election'],
            'different': ['animal', 'food', 'music']
        },
        {
            'target': 'company',
            'similar': ['corporation', 'business', 'firm'],
            'same_domain': ['market', 'economy', 'trade'],
            'different': ['animal', 'nature', 'science']
        },
        {
            'target': 'software',
            'similar': ['program', 'application', 'system'],
            'same_domain': ['computer', 'technology', 'development'],
            'different': ['animal', 'food', 'music']
        },
        {
            'target': 'war',
            'similar': ['battle', 'conflict', 'fighting'],
            'same_domain': ['military', 'soldier', 'weapon'],
            'different': ['peace', 'love', 'happiness']
        }
    ]
    
    print(f"\n2. –ê–Ω–∞–ª–∏–∑ {len(test_cases)} —Ç–µ—Å—Ç–æ–≤—ã—Ö —Å–ª—É—á–∞–µ–≤...")
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–ª—É—á–∞—è
    for i, test_case in enumerate(test_cases, 1):
        demonstrate_word_similarity(
            test_case['target'],
            test_case['similar'],
            test_case['same_domain'],
            test_case['different'],
            glove_model
        )
    
    print(f"\n{'='*80}")
    print("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"{'='*80}")

