# Лабораторная работа №1 (Сегментация и аннотация текста)

## Описание задания

Реализована система сегментации и аннотации текста, включающая:
- Сегментацию текста на предложения с учетом сокращений (Dr., Mr., Inc. и т.д.)
- Токенизацию с обработкой специальных случаев:
  - Email адреса (например: `user@example.com`)
  - Телефонные номера (например: `+7-901-000-00-00`, `8(918)3213412`)
  - Эмотиконы (например: `:)`, `:D`, `:-)`)
  - Сокращения (например: `Dr.`, `U.S.`, `it's`)
  - Обычные слова и пунктуация
- Стемминг с использованием `SnowballStemmer` из библиотеки NLTK
- Лемматизацию с использованием `WordNetLemmatizer` и POS-тегирования для повышения точности
- Проверку результатов лемматизации и поиск случаев омонимии
- Сохранение аннотаций в формате TSV с правильной структурой директорий

## Использованные технологии и инструменты

- **Датасет**: Новостные тексты на английском языке с метками классов (0, 1, 2, 3)
  - Train: 120,000 документов
  - Test: 7,600 документов
- **Модели**: 
  - `SnowballStemmer` (английский язык) для стемминга
  - `WordNetLemmatizer` для лемматизации
  - `averaged_perceptron_tagger` для определения частей речи (POS-tagging)
- **Библиотеки**: 
  - `pandas` - работа с датасетами
  - `nltk` - обработка естественного языка (токенизация, стемминг, лемматизация, POS-tagging)
  - `tqdm` - отображение прогресса обработки
  - `re` - регулярные выражения для сегментации и токенизации

## Результаты работы

- Реализована сегментация текста на предложения с корректной обработкой сокращений
- Реализована токенизация с обработкой 4+ специальных случаев (email, телефоны, эмотиконы, сокращения)
- Все документы обработаны и сохранены в формате TSV
- Структура выходных файлов соответствует требованиям:
  ```
  assets/annotated-corpus/
  ├── train/
  │   ├── 0/ (23,272 файла)
  │   ├── 1/ (21,603 файла)
  │   ├── 2/ (22,863 файла)
  │   └── 3/ (24,657 файла)
  └── test/
      ├── 0/ (1,900 файлов)
      ├── 1/ (1,900 файлов)
      ├── 2/ (1,900 файлов)
      └── 3/ (1,900 файлов)
  ```
- Проведена проверка лемматизации с выявлением случаев омонимии (словоформы, имеющие разные леммы в зависимости от части речи)

## Выводы

1. Использование POS-тегирования значительно повышает точность лемматизации по сравнению с лемматизацией без учета части речи
2. Регулярные выражения позволяют эффективно обрабатывать специальные случаи (email, телефоны, эмотиконы) как единые токены
3. Обработка сокращений в сегментации требует использования негативных просмотров (negative lookbehind) для корректного разбиения предложений
4. Для не-слов (пунктуация, числа, спецсимволы) стемма и лемма должны равняться исходному токену
5. Омонимия встречается достаточно часто в текстах, что подтверждает важность использования POS-тегов для правильной лемматизации

## Инструкция по запуску

1. Установить зависимости: 
   ```bash
   pip install -r source/requirements.txt
   ```

2. Загрузить датасет: 
   - Датасет должен быть размещен в `source/assets/raw/`
   - Файлы: `train.csv` и `test.csv`
   - Формат CSV: колонки `text` (текст документа) и `label` (метка класса)

3. Запустить скрипт: 
   ```bash
   cd source
   python main.py
   ```

4. Результаты будут сохранены в `source/assets/annotated-corpus/`:
   - `train/` - обработанные обучающие данные
   - `test/` - обработанные тестовые данные
   - Каждый документ сохранен в отдельный TSV файл в директории соответствующего класса