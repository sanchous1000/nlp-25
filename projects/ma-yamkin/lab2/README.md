# Лабораторная работа №2

## Описание задания

В лаораторной работе необходимо было векторизовать текст. После чего с использованием библиотечной реализации метода подсчета косинусного расстояния между векторными представлениями текста (для возможности получения дополнительных баллов на защите по данному пункту необходимо реализовать данный метод самостоятельно), продемонстрировать на примерах, что для семантически близких слов модель генерирует вектора, для которых косинусное расстояние меньше, чем для семантически далеких токенов. Далее необходимо было сделать пайплайн который позволит осуществить векторизацию произвольного предложения и векторизовать выборки с помощью этого пайплайна.

## Использованные технологии и инструменты
- Датасет: Базовый новостной датасет
- Модели: Word2Vec.
- Библиотеки: re, tqdm, gensim, sklearn, numpy, pandas, pathlib.

## Результаты работы

В результате работы была написана функция, позволяющая обучить векторайзер word2vec и после чего данный векторайзер был обучен на обучающей выборке.

После чего была написана функция для тестирования корректности обучения word2vec посредством определения косинусного расстояния между словами, которые обладают семантической близостью, той же предметной области и совершенно разной предметной области. Модель спраилась с данной задачей хорошо. Ниже приведены ранжированные списки различных токенов (по убыванию близости):

***ИСХОДНЫЙ ТОКЕН: HURRICANE***

  1. storm           | расстояние: 0.2925
  2. typhoon         | расстояние: 0.3553
  3. cyclone         | расстояние: 0.3851
  4. wind            | расстояние: 0.4170
  5. rain            | расстояние: 0.4226
  6. evacuation      | расстояние: 0.4780
  7. disaster        | расстояние: 0.5149
  8. flood           | расстояние: 0.6026
  9. software        | расстояние: 0.7259
  10. Olympics        | расстояние: 0.7669

***ИСХОДНЫЙ ТОКЕН: OLYMPICS***

  • mutual fund     | ❌ ТОКЕН ОТСУТСТВУЕТ В СЛОВАРЕ

  1. Games           | расстояние: 0.1425
  2. medal           | расстояние: 0.2136
  3. gymnastics      | расстояние: 0.3163
  4. athletics       | расстояние: 0.3168
  5. swimming        | расстояние: 0.3791
  6. relay           | расстояние: 0.3898
  7. judo            | расстояние: 0.4026
  8. competition     | расстояние: 0.4418
  9. nanotech        | расстояние: 0.6296
  10. mortgage        | расстояние: 0.7730

***ИСХОДНЫЙ ТОКЕН: OIL***

  1. crude           | расстояние: 0.1537
  2. petroleum       | расстояние: 0.2576
  3. OPEC            | расстояние: 0.3311
  4. gas             | расстояние: 0.3452
  5. pipeline        | расстояние: 0.4293
  6. export          | расстояние: 0.4394
  7. price           | расстояние: 0.4438
  8. dollar          | расстояние: 0.4930
  9. Venezuela       | расстояние: 0.6110
  10. bacteria        | расстояние: 0.7462

***ИСХОДНЫЙ ТОКЕН: PHISHING***

РАНЖИРОВАННЫЙ СПИСОК (ближайшие -> дальние):
  1. malware         | расстояние: 0.3155
  2. spam            | расстояние: 0.3162
  3. virus           | расстояние: 0.3458
  4. spyware         | расстояние: 0.3520
  5. email           | расстояние: 0.3811
  6. firewall        | расстояние: 0.4181
  7. hacker          | расстояние: 0.4484
  8. security        | расстояние: 0.4695
  9. tornado         | расстояние: 0.5763
  10. sprint          | расстояние: 0.7523

После этого был написан пайплайн по векторизации случайного текста и был векторизован тестовый и тренировочный датасеты. Процесс векторизации тренировочного датасета занял 30 секунд.

## Выводы
Итого:
Алгоритм word2vec корректно векторизует токены, это можно видеть исходя из того, что он различает слова из разных сфер и создает из них корректные векторы.
Время обучения word2vec на 120000 примерах составило 40 секунд.

## Инструкция по запуску
1. Установить зависимости: `pip install -r requirements.txt`
2. Запустить прошлую лабораторную работу и сохранить аннотированные корпуса в директорию ../../assets/annotated-corpus/train относительно текущей.
3. Загрузить датасет: [train.csv](https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv) в папку ../../train.csv относительно текущей.
4. Запустить скрипт: `python source/train_w2v.py` для обучения word2vec.
5. Запустить скрипт: `python source/cosine_distance.py` для подсчета косинусного расстояния между разными токенами.
6. Запустить скринт: `python source/main.py --dataset 'train'` для векторизации тренировочного датасета и `python source/main.py --dataset 'test'` для векторизации тестового датасета.
