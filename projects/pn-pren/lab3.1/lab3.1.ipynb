{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fac38cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q numpy scikit-learn pandas gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "81c313b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6794e678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "векторов w2v: (7600, 100)\n"
     ]
    }
   ],
   "source": [
    "lab1_path = \"C:/Users/Paul/Projects/nlp-25/projects/pn-pren/lab1\"\n",
    "lab2_path = \"C:/Users/Paul/Projects/nlp-25/projects/pn-pren/lab2\"\n",
    "\n",
    "embeddings_w2v = []\n",
    "labels = []\n",
    "doc_names = []\n",
    "\n",
    "with open(os.path.join(lab2_path, \"test_embeddings.tsv\"), 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        doc_id = parts[0]\n",
    "        vec = np.array([float(x) for x in parts[1:]])\n",
    "        embeddings_w2v.append(vec)\n",
    "        doc_names.append(doc_id)\n",
    "\n",
    "embeddings_w2v = np.array(embeddings_w2v)\n",
    "print(f\"векторов w2v: {embeddings_w2v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b3b8a0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "меток: 7600\n"
     ]
    }
   ],
   "source": [
    "# собираем метки для тестовой выборки\n",
    "test_path = os.path.join(lab1_path, 'test')\n",
    "class_names = ['Business', 'Sci_Tech', 'Sports', 'World']\n",
    "class_to_id = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "test_labels = []\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(test_path, class_name)\n",
    "    files = sorted([f for f in os.listdir(class_path) if f.endswith('.tsv')])\n",
    "    test_labels.extend([class_to_id[class_name]] * len(files))\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "print(f\"меток: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9aca3c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тест: (7600, 100)\n",
      "трейн: (800, 100)\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(lab1_path, 'train')\n",
    "train_embeddings_file = os.path.join(lab2_path, \"train_embeddings.npy\")\n",
    "train_labels_file = os.path.join(lab2_path, \"train_labels.npy\")\n",
    "\n",
    "if os.path.exists(train_embeddings_file) and os.path.exists(train_labels_file):\n",
    "    train_vecs_w2v = np.load(train_embeddings_file)\n",
    "    train_labels = np.load(train_labels_file)\n",
    "else:\n",
    "    from gensim.models import Word2Vec\n",
    "    \n",
    "    w2v_model = Word2Vec.load(os.path.join(lab2_path, \"word2vec.model\"))\n",
    "    \n",
    "    def load_lemmas_from_tsv(file_path):\n",
    "        lemmas = []\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 3:\n",
    "                    lemmas.append(parts[2])\n",
    "        return lemmas\n",
    "    \n",
    "    def vectorize_w2v(lemmas, model):\n",
    "        vectors = [model.wv[l] for l in lemmas if l in model.wv]\n",
    "        if not vectors:\n",
    "            return np.zeros(model.vector_size)\n",
    "        return np.mean(vectors, axis=0)\n",
    "    \n",
    "    train_vecs_w2v = []\n",
    "    train_labels = []\n",
    "    \n",
    "    docs_per_class = 200\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(train_path, class_name)\n",
    "        all_files = [f for f in os.listdir(class_path) if f.endswith('.tsv')]\n",
    "        selected_files = np.random.choice(all_files, size=docs_per_class, replace=False)\n",
    "        \n",
    "        for fname in selected_files:\n",
    "            lemmas = load_lemmas_from_tsv(os.path.join(class_path, fname))\n",
    "            train_vecs_w2v.append(vectorize_w2v(lemmas, w2v_model))\n",
    "            train_labels.append(class_to_id[class_name])\n",
    "    \n",
    "    train_vecs_w2v = np.array(train_vecs_w2v)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    np.save(train_embeddings_file, train_vecs_w2v)\n",
    "    np.save(train_labels_file, train_labels)\n",
    "\n",
    "print(f\"тест: {embeddings_w2v.shape}\")\n",
    "print(f\"трейн: {train_vecs_w2v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9e0ffc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, num_classes=4):\n",
    "    precision_per_class = []\n",
    "    recall_per_class = []\n",
    "    f1_per_class = []\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        tp = ((y_true == cls) & (y_pred == cls)).sum()\n",
    "        fp = ((y_true != cls) & (y_pred == cls)).sum()\n",
    "        fn = ((y_true == cls) & (y_pred != cls)).sum()\n",
    "        \n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        rec = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0\n",
    "        \n",
    "        precision_per_class.append(prec)\n",
    "        recall_per_class.append(rec)\n",
    "        f1_per_class.append(f1)\n",
    "    \n",
    "    precision = np.mean(precision_per_class)\n",
    "    recall = np.mean(recall_per_class)\n",
    "    f1 = np.mean(f1_per_class)\n",
    "    accuracy = (y_true == y_pred).sum() / len(y_true)\n",
    "    \n",
    "    return precision, recall, f1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1b4d0039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Linear:\n",
      "iter= 100 | prec=0.8420 | rec=0.8426 | f1=0.8421 | acc=0.8426 | time=0.01s\n",
      "iter= 500 | prec=0.8420 | rec=0.8426 | f1=0.8421 | acc=0.8426 | time=0.01s\n",
      "iter=1000 | prec=0.8420 | rec=0.8426 | f1=0.8421 | acc=0.8426 | time=0.01s\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "max_iters = [100, 500, 1000]\n",
    "\n",
    "print(\"SVM Linear:\")\n",
    "for max_iter in max_iters:\n",
    "    start = time.time()\n",
    "    clf = LinearSVC(max_iter=max_iter, random_state=42)\n",
    "    clf.fit(train_vecs_w2v, train_labels)\n",
    "    train_time = time.time() - start\n",
    "    \n",
    "    y_pred = clf.predict(embeddings_w2v)\n",
    "    prec, rec, f1, acc = calculate_metrics(test_labels, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'model': 'SVM-linear',\n",
    "        'vectors': 'w2v',\n",
    "        'max_iter': max_iter,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1,\n",
    "        'accuracy': acc,\n",
    "        'train_time': train_time\n",
    "    })\n",
    "    \n",
    "    print(f\"iter={max_iter:4d} | prec={prec:.4f} | rec={rec:.4f} | f1={f1:.4f} | acc={acc:.4f} | time={train_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cdde47ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6fb37cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM RBF:\n",
      "iter= 100 | prec=0.8583 | rec=0.8586 | f1=0.8581 | acc=0.8586 | time=0.01s\n",
      "iter= 500 | prec=0.8584 | rec=0.8588 | f1=0.8584 | acc=0.8588 | time=0.01s\n",
      "iter=1000 | prec=0.8584 | rec=0.8588 | f1=0.8584 | acc=0.8588 | time=0.01s\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM RBF:\")\n",
    "for max_iter in [100, 500, 1000]:\n",
    "    start = time.time()\n",
    "    clf = SVC(kernel='rbf', max_iter=max_iter, random_state=42)\n",
    "    clf.fit(train_vecs_w2v, train_labels)\n",
    "    train_time = time.time() - start\n",
    "    \n",
    "    y_pred = clf.predict(embeddings_w2v)\n",
    "    prec, rec, f1, acc = calculate_metrics(test_labels, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'model': 'SVM-rbf',\n",
    "        'vectors': 'w2v',\n",
    "        'max_iter': max_iter,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1,\n",
    "        'accuracy': acc,\n",
    "        'train_time': train_time\n",
    "    })\n",
    "    \n",
    "    print(f\"iter={max_iter:4d} | prec={prec:.4f} | rec={rec:.4f} | f1={f1:.4f} | acc={acc:.4f} | time={train_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1e0cdcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Poly:\n",
      "iter= 100 | prec=0.8594 | rec=0.8599 | f1=0.8595 | acc=0.8599 | time=0.01s\n",
      "iter= 500 | prec=0.8613 | rec=0.8614 | f1=0.8611 | acc=0.8614 | time=0.01s\n",
      "iter=1000 | prec=0.8613 | rec=0.8614 | f1=0.8611 | acc=0.8614 | time=0.01s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSVM Poly:\")\n",
    "for max_iter in [100, 500, 1000]:\n",
    "    start = time.time()\n",
    "    clf = SVC(kernel='poly', degree=3, max_iter=max_iter, random_state=42)\n",
    "    clf.fit(train_vecs_w2v, train_labels)\n",
    "    train_time = time.time() - start\n",
    "    \n",
    "    y_pred = clf.predict(embeddings_w2v)\n",
    "    prec, rec, f1, acc = calculate_metrics(test_labels, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'model': 'SVM-poly',\n",
    "        'vectors': 'w2v',\n",
    "        'max_iter': max_iter,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1,\n",
    "        'accuracy': acc,\n",
    "        'train_time': train_time\n",
    "    })\n",
    "    \n",
    "    print(f\"iter={max_iter:4d} | prec={prec:.4f} | rec={rec:.4f} | f1={f1:.4f} | acc={acc:.4f} | time={train_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a56e716e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     model vectors  max_iter  precision   recall       f1  accuracy  train_time\n",
      "SVM-linear     w2v       100   0.841968 0.842632 0.842135  0.842632    0.009505\n",
      "SVM-linear     w2v       500   0.841968 0.842632 0.842135  0.842632    0.009510\n",
      "SVM-linear     w2v      1000   0.841968 0.842632 0.842135  0.842632    0.008011\n",
      "   SVM-rbf     w2v       100   0.858342 0.858553 0.858119  0.858553    0.007022\n",
      "   SVM-rbf     w2v       500   0.858435 0.858816 0.858386  0.858816    0.007708\n",
      "   SVM-rbf     w2v      1000   0.858435 0.858816 0.858386  0.858816    0.008003\n",
      "  SVM-poly     w2v       100   0.859385 0.859868 0.859495  0.859868    0.006510\n",
      "  SVM-poly     w2v       500   0.861274 0.861447 0.861116  0.861447    0.007153\n",
      "  SVM-poly     w2v      1000   0.861274 0.861447 0.861116  0.861447    0.006510\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4b0bf805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Лучший результат по F1:\n",
      "Модель: SVM-poly\n",
      "Векторы: w2v\n",
      "Итерации: 500\n",
      "F1: 0.8611\n",
      "Accuracy: 0.8614\n"
     ]
    }
   ],
   "source": [
    "best_result = df_results.loc[df_results['f1'].idxmax()]\n",
    "print(f\"\\nЛучший результат по F1:\")\n",
    "print(f\"Модель: {best_result['model']}\")\n",
    "print(f\"Векторы: {best_result['vectors']}\")\n",
    "print(f\"Итерации: {best_result['max_iter']}\")\n",
    "print(f\"F1: {best_result['f1']:.4f}\")\n",
    "print(f\"Accuracy: {best_result['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "65b38d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Лучший результат по accuracy:\n",
      "Модель: SVM-poly\n",
      "Векторы: w2v\n",
      "Итерации: 500\n",
      "F1: 0.8611\n",
      "Accuracy: 0.8614\n"
     ]
    }
   ],
   "source": [
    "best_result = df_results.loc[df_results['accuracy'].idxmax()]\n",
    "print(f\"\\nЛучший результат по accuracy:\")\n",
    "print(f\"Модель: {best_result['model']}\")\n",
    "print(f\"Векторы: {best_result['vectors']}\")\n",
    "print(f\"Итерации: {best_result['max_iter']}\")\n",
    "print(f\"F1: {best_result['f1']:.4f}\")\n",
    "print(f\"Accuracy: {best_result['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7f9cae1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отбрасывание случайных размерностей:\n",
      "отброшено=10 | осталось= 90 | f1=0.8426 | acc=0.8432\n",
      "отброшено=20 | осталось= 80 | f1=0.8342 | acc=0.8349\n",
      "отброшено=30 | осталось= 70 | f1=0.8279 | acc=0.8288\n",
      "отброшено=40 | осталось= 60 | f1=0.8197 | acc=0.8208\n",
      "отброшено=50 | осталось= 50 | f1=0.8219 | acc=0.8225\n"
     ]
    }
   ],
   "source": [
    "print(\"Отбрасывание случайных размерностей:\")\n",
    "\n",
    "best_iter = int(best_result['max_iter'])\n",
    "drop_dims = [10, 20, 30, 40, 50]\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "for n_drop in drop_dims:\n",
    "    keep_indices = np.random.choice(train_vecs_w2v.shape[1], \n",
    "                                   train_vecs_w2v.shape[1] - n_drop, \n",
    "                                   replace=False)\n",
    "    \n",
    "    X_train_mod = train_vecs_w2v[:, keep_indices]\n",
    "    X_test_mod = embeddings_w2v[:, keep_indices]\n",
    "    \n",
    "    start = time.time()\n",
    "    clf = LinearSVC(max_iter=best_iter, random_state=42)\n",
    "    clf.fit(X_train_mod, train_labels)\n",
    "    train_time = time.time() - start\n",
    "    \n",
    "    y_pred = clf.predict(X_test_mod)\n",
    "    prec, rec, f1, acc = calculate_metrics(test_labels, y_pred)\n",
    "    \n",
    "    print(f\"отброшено={n_drop:2d} | осталось={X_train_mod.shape[1]:3d} | f1={f1:.4f} | acc={acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (VS Code)",
   "language": "python",
   "name": "kernel3_12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
