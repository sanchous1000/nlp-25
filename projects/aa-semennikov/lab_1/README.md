# Лабораторная работа №1

## Описание задания

В ходе выполнения лабораторной работы был реализован следующий конвейер обработки исходного текста: 

* сегментация предложений
* токенизация предложений
* стемминг
* лемматизация
* формирование аннотированного корпуса

Использовался базовый новостной датасет, содержащий документы, размеченные по категориям. Для каждого документа был сформирован отдельный TSV-файл с трёхколоночной структурой:

`<токен> <стемма> <лемма>`

Отдельно обрабатывались сложные паттерны, такие как:

* адреса email
* номера телефонов
* уважительные обращения
* адреса веб-сайтов

## Использованные технологии и инструменты
- Модели: SnowballStemmer, WordNetLemmatizer
- Библиотеки: pandas, nltk, pathlib, re

## Результаты работы

Все документы датасета, включая содержащиеся в них сложные паттерны, были корректно обработаны. Убедиться в этом, а также рассмотреть на примере обработку омонимов можно посредством функции `main_solo_case()`. 

В предложении "He saw the saw he had left on the left of the nearest log." были правильно выделены две словоформы `left`: `left` (слева) и `leave`(оставить, покинуть). Однако, для слова `saw` (увидел/пила) не была выделена лемма `see`, что, вероятно, связано с несовершенством WordNetLemmatizer (POS-tags были определены верно) при обработке неправильных глаголов (irregular verbs) в английском языке.

* Для каждого документа был сгенерирован TSV-файл в заданном формате.

Пример фрагмента аннотации:

```
Reuters	reuter	reuters
Venezuelans	venezuelan	venezuelan
turned	turn	turn
out	out	out
early	earli	early
```
**Время работы:**

- Тренировочный набор: 120000 строк, 412.94 сек. (6.88 минут)
- Тестовый набор: 7600 строк, 27.93 сек.

## Выводы

* Регулярные выражения являются неплохим baseline решением для токенизации текста и, в частности, обработки таких паттернов в тексте, как телефонные номера, обращения, адреса веб-страниц и электронной почты.
* При лемматизации в зависимости от части речи выделяются начальные словоформы. В некоторых случаях омонимии словоформы могут выделяться с ошибкой.

## Инструкция по запуску
1. Установить зависимости командой `pip install -r requirements.txt`
2. Загрузить датасет: 
   1. [train.csv](https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv)
   2. [test.csv](https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/test.csv)
3. Запустить скрипт: `python source/main.py`