# Лабораторная работа №1  
## Сегментация и аннотация текста

## Описание задания

В рамках лабораторной работы была реализована система сегментации и аннотации текста, включающая:
- сегментацию текста на предложения на основе регулярных выражений;
- токенизацию предложений с корректной обработкой сложных случаев;
- стемминг и лемматизацию токенов с использованием существующих NLP-библиотек;
- формирование аннотированного корпуса в формате TSV.

В качестве исходного корпуса был использован датасет IMDb с текстами отзывов о фильмах.  
Результатом работы является аннотированный корпус, в котором каждому токену сопоставлены его основа (stem) и лемма.

---

## Использованные технологии и инструменты

- **Датасет**:
  - IMDb Movie Reviews (Stanford NLP, HuggingFace Datasets)

- **Библиотеки и инструменты**:
  - Python 3.x
  - `re` — регулярные выражения
  - `pandas` — работа с датасетом
  - `nltk`:
    - `PorterStemmer` — стемминг
    - `WordNetLemmatizer` — лемматизация
    - `stopwords` — стоп-слова
  - Jupyter Notebook (`main.ipynb`)

- **Реализованные модули**:
  - `SentenceSegmenter` — сегментация текста на предложения
  - `TextTokenizer` — токенизация с поддержкой сложных случаев
  - `TextProcessor` — полный пайплайн обработки текста

---

## Результаты работы

### Сегментация предложений

Реализован сегментатор предложений, корректно обрабатывающий случаи, которые не должны приводить к разрыву предложения:
- сокращения (`Dr.`, `Mr.`, `etc.`);
- временные форматы (`2:30 p.m.`);
- десятичные числа (`3.14`);
- версии (`v2.1.3`);
- адреса электронной почты и URL.

Для этого используется механизм *защиты* (временной подмены точек), предотвращающий ложные разрывы.

---

### Токенизация

Токенизатор основан на регулярных выражениях и поддерживает защиту сложных токенов, которые обрабатываются как единое целое:
- электронные почты (`test@example.com`);
- URL (`https://example.com`);
- телефонные номера;
- эмотиконы (`:)`, `:(`);
- хештеги и упоминания (`#NLP`, `@user`);
- денежные суммы и проценты (`$19.99`, `15%`);
- сокращения и дефисные слова (`state-of-the-art`).

Токенизация производится после защиты специальных паттернов, с последующим восстановлением исходных токенов.

---

### Стемминг и лемматизация

Для каждого токена:
- применяется **стемминг** с использованием `PorterStemmer`;
- применяется **лемматизация** с использованием `WordNetLemmatizer`.

Для несловесных токенов (числа, специальные символы) исходная форма сохраняется без изменений.

---

### Проверка лемматизации и омонимия

В процессе лемматизации наблюдаются случаи омонимии, обусловленные отсутствием контекста и информации о части речи.  
Например:
- слово `saw` может интерпретироваться как:
  - глагол *see* (прошедшее время),
  - существительное *saw* (пила) (наш случай);
- слово `better` может быть прилагательным или наречием.

Используемый лемматизатор (`WordNetLemmatizer`) по умолчанию предполагает существительное, что объясняет полученные результаты.

---

### Формирование аннотированного корпуса

Для каждого документа формируется файл в формате TSV со структурой:

```

<token>    <stem>    <lemma>

```

Аннотации:
- токены внутри предложения разделяются переводом строки;
- предложения разделяются пустой строкой;
- документы разделены по классам (`pos`, `neg`) и разбиению (`train`, `test`).

Итоговая структура:
```

assets/
└── annotated-corpus/
├── train/
│   ├── pos/
│   └── neg/
└── test/
    ├── pos/
    └── neg/

````

---

## Выводы

В ходе выполнения лабораторной работы была реализована полноценная система сегментации и аннотации текста на основе регулярных выражений и классических NLP-инструментов.

Основные результаты:
- реализована устойчивая сегментация предложений с учетом сложных случаев;
- создан токенизатор, корректно обрабатывающий широкий спектр специальных токенов;
- выполнены стемминг и лемматизация текста;
- сформирован аннотированный корпус в соответствии с заданным форматом.

Основные ограничения:
- лемматизация выполняется без учета контекста и части речи, что приводит к омонимии;

В целом, поставленные в лабораторной работе требования выполнены в полном объеме.

---

## Инструкция по запуску

1. Установить зависимости:
```bash
pip install pandas nltk
````

2. Загрузить необходимые ресурсы NLTK (выполняется автоматически в `main.ipynb`):

```python
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('stopwords')
```

3. Выполнить все ячейки ноутбука main.ipynb:

* загрузка датасета IMDb;
* сегментация и токенизация текста;
* стемминг и лемматизация;
* формирование аннотированных файлов в директории `assets/annotated-corpus`.

Результаты аннотации будут сохранены в соответствии с требованиями лабораторной работы.