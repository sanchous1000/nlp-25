# Лабораторная работа №1

Разработка пайплайна обработки текста для англоязычного новостного датасета. Пайплайн включает следующие этапы:
- Сегментация текста
- Токенизация с обработкой паттернов
- Стемминг
- Лемматизация
- Сохранение аннотаций в формате TSV

## 1. Использованные технологии и инструменты

### Библиотеки

| Библиотека | Назначение |
|------------|------------|
| **NLTK** | Основная библиотека для NLP-обработки |
| **SnowballStemmer** | Стемминг (алгоритм Porter2) |
| **WordNetLemmatizer** | Лемматизация с учётом части речи |
| **POS Tagger** | Определение частей речи для контекстной лемматизации |

### Датасет

Был выбран базовый новостной датасет из предложенных в [указаниях к выполнению лабораторных работ](https://github.com/sanchous1000/nlp-25/blob/main/tasks/README.md)

| Параметр | Значение |
|----------|----------|
| Обучающая выборка | 120 000 документов |
| Тестовая выборка | 7 600 документов |
| Количество классов | 4 |

**Классы:**
1. Мировые новости
2. Спорт
3. Бизнес
4. Наука и технологии

### Структура проекта

```
├── assets/
│   └── annotated-corpus/
│       ├── train/
│       │   ├── 1/
│       │   ├── 2/
│       │   ├── 3/
│       │   └── 4/
│       └── test/
│           ├── 1/
│           ├── 2/
│           ├── 3/
│           └── 4/
├── dataset/
│   ├── train.csv
│   └── test.csv
└── lab1/
    ├── source/
    │   ├── main.py
    │   ├── nlp.py
    │   ├── utils.py
    │   ├── test_tokenizer.py
    │   └── requirements.txt
    └── README.md

```

## 2. Результаты работы

### Токенизатор

Реализован токенизатор на основе регулярных выражений, обрабатывающий паттерны:

| Тип паттерна | Пример |
|--------------|--------|
| Email-адреса | `support@example.com` |
| Web-адреса | `https://2ip.io` |
| Телефоны (US) | `1-800-555-1234`, `(555) 123-4567` |
| Сокращения | `Dr.`, `Mr.`, `Mrs.`, `St.`, `Inc.` |
| Эмотиконы | `:)`, `:(`, `;-)`, `^_^`, `<3` |
| Валюта | `$50.99`, `€25,000`, `$1.5 billion` |
| Сокращения | `can't`, `it's`, `they're` |
| Хэштеги/Упоминания | `#MachineLearning`, `@johndoe` |
| Даты | `12/31/2024`, `2024-01-15` |
| Проценты | `50%`, `3.5%` |

### Сегментация

Сегментатор использует регулярные выражения со специальной обработкой:
- Сокращений, не завершающих предложения (Dr., Mr., Inc., U.S. и др.)
- Кавычек и вложенной пунктуации
- Множественных знаков препинания в конце предложения

### Стемминг и лемматизация

| Метод | Алгоритм | Пример |
|-------|----------|--------|
| Стемминг | SnowballStemmer (Porter2) | `running` → `run`, `successfully` → `success` |
| Лемматизация | WordNetLemmatizer + POS | `are` → `be`, `companies` → `company` |


## 3. Выводы

### Обработка неоднозначности при лемматизации

Примеры омонимии встречаемые в датасете:

| Слово | Как существительное | Как глагол |
|-------|---------------------|------------|
| `saw` | `saw` (пила) | `see` (видеть) |
| `leaves` | `leaf` (лист) | `leave` (уходить) |
| `meeting` | `meeting` (встреча) | `meet` (встречать) |
| `banks` | `bank` (банк) | `bank` (делать вклад) |

**Решение:** Использование POS-теггера NLTK для определения наиболее вероятной части речи токена в контексте.

## 4. Инструкция по запуску

### Установка зависимостей

```bash
pip install -r lab1/source/requirements.txt
```

### Генерация аннотаций

```bash
cd /workspaces/nlp-25/projects/aa-kalinin
python lab1/source/pipeline.py \
    --dataset-dir ./dataset \
    --output-dir ./assets/annotated-corpus
```

### Генерация отчёта по лемматизации

```bash
python lab1/source/pipeline.py --report
```

### Запуск тестов токенизатора

```bash
cd lab1/source
python test_tokenizer.py
```
