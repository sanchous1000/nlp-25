# Лабораторная работа №3.1: Классификация текстов

## Описание задания
В данной лабораторной работе была проведена классификация текстов новостей на 4 категории с использованием метода опорных векторов (SVM). Были загружены предобученные эмбеддинги документов и соответствующие метки из датасета AG News. Проведены эксперименты с разными ядрами SVM и количеством итераций, а также исследовано влияние отбрасывания части размерностей эмбеддингов на качество классификации.

## Использованные технологии и инструменты
- **Датасет:** AG News (через Hugging Face Datasets)
- **Модель:** SVM (Support Vector Machine) из библиотеки scikit-learn
- **Библиотеки:** 
  - `datasets` – загрузка датасетов
  - `numpy` – работа с массивами
  - `scikit-learn` – машинное обучение, разделение данных, метрики
  - `time` – замер времени обучения

## Результаты работы
Были проведены эксперименты с двумя типами ядер SVM (`linear` и `rbf`) и разным количеством итераций (200, 500, 1000). Также исследовано влияние уменьшения размерности эмбеддингов путём зануления случайных признаков.

### Основные результаты:
- Наилучшая точность (`accuracy`) достигается при использовании линейного ядра и составляет **0.85–0.90** в зависимости от количества отброшенных признаков.
- При отбрасывании 50% признаков точность повысилась до **0.90**, что может указывать на наличие шумовых признаков в исходных эмбеддингах.
- Время обучения моделей составляет менее **0.01 секунды** на урезанном наборе данных из 100 примеров.

### Метрики качества (усреднённые по классам):
  - `precision`: 0.21–0.47  
  - `recall`: 0.25–0.33  
  - `f1-score`: 0.23–0.36  

## Выводы
1. Линейное ядро SVM показало стабильно высокую точность классификации на данном наборе.
2. Уменьшение размерности эмбеддингов не всегда приводит к снижению качества — в некоторых случаях наблюдается улучшение метрик, что может быть связано с устранением шумовых признаков.
3. Модель обучается очень быстро благодаря небольшому объёму данных и низкой размерности эмбеддингов (100 признаков).
4. Для более надёжных выводов необходимо провести эксперименты на полном датасете (120k примеров) и использовать кросс-валидацию.

## Инструкция по запуску

### 1. Установите зависимости:
```bash
pip install -r requirements.txt
```

### 2. Подготовьте данные:
- Убедитесь, что в директории с проектом есть файл document_vectors.tsv с эмбеддингами документов.
- Датасет AG News будет загружен автоматически при первом запуске.

### 3. Запустите ноутбук:
- Откройте LR3.1.ipynb в Jupyter Notebook.
- Выполните ячейки последовательно.

*Примечание*: Файл document_vectors.tsv взят из результатов лабораторной работы №2.