{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 3.2 - Topic Modeling (Тематическое моделирование)\n",
        "\n",
        "This notebook demonstrates the complete topic modeling pipeline:\n",
        "1. Loading term-document matrix from Lab 2\n",
        "2. LDA experiments with different numbers of topics\n",
        "3. Perplexity analysis and polynomial approximation\n",
        "4. Finding optimal number of topics\n",
        "5. Document-topic probability analysis\n",
        "6. Iteration count experiments\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "# Add source directory to path\n",
        "sys.path.append('source')\n",
        "\n",
        "from source.data_loader import load_vocabulary_from_lab2, split_train_test\n",
        "from source.topic_modeling import TopicModeler\n",
        "from source.experiments import run_lda_experiments, run_iteration_experiments\n",
        "from source.analysis import plot_perplexity_vs_topics, find_optimal_topics, polynomial_approximation\n",
        "\n",
        "# Set up plotting style\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "except:\n",
        "    try:\n",
        "        plt.style.use('seaborn')\n",
        "    except:\n",
        "        pass\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Term-Document Matrix from Lab 2\n",
        "\n",
        "Load the term-document matrix and vocabulary that were created in Lab 2 Task 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading term-document matrix and vocabulary from lab2...\n",
            "Stop word filtering: ENABLED\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "Token dictionary not found at ../lab2\\assets\\token_dictionary.pkl. Please run Lab 2 Task 1 first.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStop word filtering: DISABLED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m dict_data, term_doc_matrix, vocabulary \u001b[38;5;241m=\u001b[39m load_vocabulary_from_lab2(\n\u001b[0;32m     13\u001b[0m     lab2_dir, \n\u001b[0;32m     14\u001b[0m     filter_stopwords\u001b[38;5;241m=\u001b[39mfilter_stopwords\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTerm-document matrix shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mterm_doc_matrix\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVocabulary size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(vocabulary)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32me:\\D\\AI\\Semester 3\\text processing\\nlp-25\\projects\\mt-desta\\lab3.2\\source\\data_loader.py:229\u001b[0m, in \u001b[0;36mload_vocabulary_from_lab2\u001b[1;34m(lab2_dir, filter_stopwords)\u001b[0m\n\u001b[0;32m    226\u001b[0m matrix_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(lab2_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massets\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mterm_document_matrix.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(dict_file):\n\u001b[1;32m--> 229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken dictionary not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdict_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run Lab 2 Task 1 first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m     )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(matrix_file):\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTerm-document matrix not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmatrix_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run Lab 2 Task 1 first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m     )\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: Token dictionary not found at ../lab2\\assets\\token_dictionary.pkl. Please run Lab 2 Task 1 first."
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "lab2_dir = \"../lab2\"\n",
        "filter_stopwords = True  # Set to False to keep all words\n",
        "\n",
        "# Load term-document matrix and vocabulary\n",
        "print(\"Loading term-document matrix and vocabulary from lab2...\")\n",
        "if filter_stopwords:\n",
        "    print(\"Stop word filtering: ENABLED\")\n",
        "else:\n",
        "    print(\"Stop word filtering: DISABLED\")\n",
        "\n",
        "dict_data, term_doc_matrix, vocabulary = load_vocabulary_from_lab2(\n",
        "    lab2_dir, \n",
        "    filter_stopwords=filter_stopwords\n",
        ")\n",
        "\n",
        "print(f\"\\nTerm-document matrix shape: {term_doc_matrix.shape}\")\n",
        "print(f\"Vocabulary size: {len(vocabulary)}\")\n",
        "print(f\"Number of documents: {term_doc_matrix.shape[1]}\")\n",
        "print(f\"\\nSample vocabulary words (first 20): {vocabulary[:20]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Split into Train and Test Sets\n",
        "\n",
        "Split the term-document matrix for training and evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split into train and test\n",
        "train_matrix, test_matrix = split_train_test(term_doc_matrix, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Train matrix: {train_matrix.shape}\")\n",
        "print(f\"Test matrix: {test_matrix.shape}\")\n",
        "print(f\"Train documents: {train_matrix.shape[1]}\")\n",
        "print(f\"Test documents: {test_matrix.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Task 1 - LDA Experiments with Different Numbers of Topics\n",
        "\n",
        "Run LDA experiments with varying numbers of topics. The dataset has 4 classes, so we'll test: 2, 4, 5, 10, 20, 40 topics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Number of classes in dataset (AG News has 4 classes)\n",
        "num_classes = 4\n",
        "\n",
        "# List of topics to test (including number of classes)\n",
        "n_topics_list = [2, 5, 10, 20, 40]\n",
        "if num_classes not in n_topics_list:\n",
        "    n_topics_list.append(num_classes)\n",
        "n_topics_list = sorted(n_topics_list)\n",
        "\n",
        "print(f\"Testing number of topics: {n_topics_list}\")\n",
        "\n",
        "# Run experiments\n",
        "results = run_lda_experiments(\n",
        "    train_matrix, test_matrix,\n",
        "    vocabulary, n_topics_list,\n",
        "    n_iter=10\n",
        ")\n",
        "\n",
        "print(f\"\\nCompleted {len(results)} experiments\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Display Top Words for Each Topic\n",
        "\n",
        "Show the top 10 keywords for each topic from one of the experiments.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display top words for experiment with 10 topics\n",
        "result_10 = next((r for r in results if r['n_topics'] == 10), None)\n",
        "\n",
        "if result_10:\n",
        "    print(f\"Top 10 words for each topic (n_topics=10):\")\n",
        "    print(\"=\" * 60)\n",
        "    for topic_id, words in result_10['top_words'].items():\n",
        "        print(f\"\\nTopic {topic_id}:\")\n",
        "        for i, (word, prob) in enumerate(words, 1):\n",
        "            print(f\"  {i:2d}. {word:15s} (prob: {prob:.6f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Task 2 - Perplexity Analysis with Polynomial Approximation\n",
        "\n",
        "Plot perplexity vs number of topics and fit a polynomial curve using r-squared metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot perplexity vs topics with polynomial approximation\n",
        "coefs, r2, degree, best_reg, best_poly_features = plot_perplexity_vs_topics(results)\n",
        "\n",
        "print(f\"\\nPolynomial Approximation Results:\")\n",
        "print(f\"  Best degree: {degree}\")\n",
        "print(f\"  R-squared: {r2:.4f}\")\n",
        "print(f\"  Coefficients: {coefs}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Task 3 - Find Optimal Number of Topics\n",
        "\n",
        "Determine the optimal number of topics using different methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find optimal number of topics\n",
        "optimal_topics_elbow = find_optimal_topics(results, method='elbow')\n",
        "optimal_topics_min = find_optimal_topics(results, method='min_perplexity')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Optimal Number of Topics Analysis\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nElbow method: {optimal_topics_elbow} topics\")\n",
        "print(f\"Minimum perplexity: {optimal_topics_min} topics\")\n",
        "\n",
        "# Show perplexity for each configuration\n",
        "print(\"\\nPerplexity by number of topics:\")\n",
        "print(\"-\" * 60)\n",
        "for r in sorted(results, key=lambda x: x['n_topics']):\n",
        "    print(f\"  {r['n_topics']:2d} topics: {r['perplexity']:8.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Document-Topic Probability Analysis\n",
        "\n",
        "Examine document-topic probability distributions for the optimal model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get document-topic distribution for optimal model\n",
        "optimal_result = next((r for r in results if r['n_topics'] == optimal_topics_elbow), results[0])\n",
        "doc_topic_dist = np.array(optimal_result['doc_topic_distribution'])\n",
        "\n",
        "print(f\"Document-topic distribution shape: {doc_topic_dist.shape}\")\n",
        "print(f\"Number of documents: {doc_topic_dist.shape[0]}\")\n",
        "print(f\"Number of topics: {doc_topic_dist.shape[1]}\")\n",
        "\n",
        "# Show statistics\n",
        "print(\"\\nTopic probability statistics:\")\n",
        "print(\"-\" * 60)\n",
        "for topic_idx in range(doc_topic_dist.shape[1]):\n",
        "    topic_probs = doc_topic_dist[:, topic_idx]\n",
        "    print(f\"Topic {topic_idx}: mean={np.mean(topic_probs):.4f}, \"\n",
        "          f\"std={np.std(topic_probs):.4f}, max={np.max(topic_probs):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Top Documents per Topic\n",
        "\n",
        "Show documents with highest probability for each topic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display top documents for each topic\n",
        "print(f\"Top 5 documents for each topic (n_topics={optimal_result['n_topics']}):\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for topic_id, docs in optimal_result['top_documents'].items():\n",
        "    print(f\"\\nTopic {topic_id}:\")\n",
        "    for i, (doc_idx, prob) in enumerate(docs[:5], 1):\n",
        "        print(f\"  {i}. Document {doc_idx:5d} (probability: {prob:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Optional - Iteration Count Experiments\n",
        "\n",
        "Test different numbers of training iterations to find optimal value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different iteration counts\n",
        "base_iter = 10\n",
        "n_iters_list = [base_iter // 2, base_iter, base_iter * 2]\n",
        "test_n_topics = optimal_topics_elbow\n",
        "\n",
        "print(f\"Testing iteration counts: {n_iters_list}\")\n",
        "print(f\"Using {test_n_topics} topics (optimal from previous experiments)\")\n",
        "\n",
        "iter_results = run_iteration_experiments(\n",
        "    train_matrix, test_matrix,\n",
        "    vocabulary, test_n_topics,\n",
        "    n_iters_list\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize iteration results\n",
        "iter_df = pd.DataFrame(iter_results)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Perplexity vs iterations\n",
        "axes[0].plot(iter_df['n_iter'], iter_df['perplexity'], marker='o', linewidth=2, markersize=10)\n",
        "axes[0].set_xlabel('Number of Iterations', fontsize=12)\n",
        "axes[0].set_ylabel('Perplexity', fontsize=12)\n",
        "axes[0].set_title('Perplexity vs Number of Iterations', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Training time vs iterations\n",
        "axes[1].plot(iter_df['n_iter'], iter_df['training_time'], marker='s', linewidth=2, markersize=10, color='orange')\n",
        "axes[1].set_xlabel('Number of Iterations', fontsize=12)\n",
        "axes[1].set_ylabel('Training Time (seconds)', fontsize=12)\n",
        "axes[1].set_title('Training Time vs Number of Iterations', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find optimal iterations\n",
        "best_iter_result = min(iter_results, key=lambda x: x['perplexity'])\n",
        "print(f\"\\nOptimal number of iterations: {best_iter_result['n_iter']}\")\n",
        "print(f\"  Perplexity: {best_iter_result['perplexity']:.2f}\")\n",
        "print(f\"  Training time: {best_iter_result['training_time']:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Save Results\n",
        "\n",
        "Save experiment results and document-topic distributions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results\n",
        "os.makedirs('assets/results', exist_ok=True)\n",
        "os.makedirs('assets/results/distributions', exist_ok=True)\n",
        "\n",
        "# Save experiment results\n",
        "results_file = 'assets/results/lda_experiments.json'\n",
        "with open(results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "print(f\"Saved experiment results to {results_file}\")\n",
        "\n",
        "# Save document-topic distributions in TSV format\n",
        "for result in results:\n",
        "    n_topics = result['n_topics']\n",
        "    doc_topic_dist = np.array(result['doc_topic_distribution'])\n",
        "    \n",
        "    output_file = f'assets/results/distributions/doc_topic_dist_n_topics_{n_topics}.tsv'\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        for doc_idx, probs in enumerate(doc_topic_dist):\n",
        "            doc_id = str(doc_idx)\n",
        "            prob_str = '\\t'.join([f\"{p:.6f}\" for p in probs])\n",
        "            f.write(f\"{doc_id}\\t{prob_str}\\n\")\n",
        "    \n",
        "    print(f\"Saved document-topic distribution to {output_file}\")\n",
        "\n",
        "print(\"\\nAll results saved successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
